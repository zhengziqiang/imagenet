

﻿﻿在深度学习的实际应用中，我们经常用到的原始数据是图片文件，如jpg,jpeg,png,tif等格式的，而且有可能图片的大小还不一致。而在caffe中经常使用的数据类型是lmdb或leveldb，因此就产生了这样的一个问题：如何从原始图片文件转换成caffe中能够运行的db（leveldb/lmdb)文件？前面文章有学习过着个数据由来和使用。

在caffe中，作者为我们提供了这样一个文件：convert_imageset.cpp，存放在根目录下的tools文件夹下。编译之后，生成对应的可执行文件放在 buile/tools/ 下面，这个文件的作用就是用于将图片文件转换成caffe框架中能直接使用的db文件。

该文件的使用格式：

[cpp] view plain copy

    convert_imageset [FLAGS] ROOTFOLDER/ LISTFILE DB_NAME  

需要带四个参数：

FLAGS: 图片参数组，后面详细介绍

ROOTFOLDER/: 图片存放的绝对路径，从linux系统根目录开始

LISTFILE: 图片文件列表清单，一般为一个txt文件，一行一张图片

DB_NAME: 最终生成的db文件存放目录

如果图片已经下载到本地电脑上了，那么我们首先需要创建一个图片列表清单，保存为txt

本文以caffe程序中自带的图片为例，进行讲解，图片目录是  example/images/, 两张图片，一张为cat.jpg, 另一张为fish_bike.jpg，表示两个类别。

我们创建一个sh脚本文件，调用linux命令来生成图片清单：

[cpp] view plain copy

    # sudo vi examples/images/create_filelist.sh  

编辑这个文件,输入下面的代码并保存

[cpp] view plain copy

    # /usr/bin/env sh  
    DATA=examples/images  
    echo "Create train.txt..."  
    rm -rf $DATA/train.txt  
    find $DATA -name *cat.jpg | cut -d '/' -f3 | sed "s/$/ 1/">>$DATA/train.txt  
    find $DATA -name *bike.jpg | cut -d '/' -f3 | sed "s/$/ 2/">>$DATA/tmp.txt  
    cat $DATA/tmp.txt>>$DATA/train.txt  
    rm -rf $DATA/tmp.txt  
    echo "Done.."  

这个脚本文件中，用到了rm,find, cut, sed,cat等linux命令。

rm: 删除文件

find: 寻找文件

cut: 截取路径

sed: 在每行的最后面加上标注。本例中将找到的*cat.jpg文件加入标注为1，找到的*bike.jpg文件加入标注为2

cat: 将两个类别合并在一个文件里。

最终生成如下的一个train.txt文件：

cat.jpg 1
fish-bike.jpg 2

当然，图片很少的时候，手动编写这个列表清单文件就行了。但图片很多的情况，就需要用脚本文件来自动生成了。在以后的实际应用中，还需要生成相应的val.txt和test.txt文件，方法是一样的。

生成的这个train.txt文件，就可以作为第三个参数，直接使用了。

接下来，我们来了解一下FLAGS这个参数组，有些什么内容：

-gray: 是否以灰度图的方式打开图片。程序调用opencv库中的imread()函数来打开图片，默认为false

-shuffle: 是否随机打乱图片顺序。默认为false

-backend:需要转换成的db文件格式，可选为leveldb或lmdb,默认为lmdb

-resize_width/resize_height: 改变图片的大小。在运行中，要求所有图片的尺寸一致，因此需要改变图片大小。 程序调用opencv库的resize（）函数来对图片放大缩小，默认为0，不改变

-check_size: 检查所有的数据是否有相同的尺寸。默认为false,不检查

-encoded: 是否将原图片编码放入最终的数据中，默认为false

-encode_type: 与前一个参数对应，将图片编码为哪一个格式：‘png','jpg'......

好了，知道这些参数后，我们就可以调用命令来生成最终的lmdb格式数据了

由于参数比较多，因此我们可以编写一个sh脚本来执行命令：

首先，创建sh脚本文件：

# sudo vi examples/images/create_lmdb.sh

编辑，输入下面的代码并保存

[cpp] view plain copy

    #!/usr/bin/en sh  
    DATA=examples/images  
    rm -rf $DATA/img_train_lmdb  
    build/tools/convert_imageset --shuffle \  
    --resize_height=256 --resize_width=256 \  
    /home/xxx/caffe/examples/images/ $DATA/train.txt  $DATA/img_train_lmdb  

设置参数-shuffle,打乱图片顺序。设置参数-resize_height和-resize_width将所有图片尺寸都变为256*256.

/home/xxx/caffe/examples/images/ 为图片保存的绝对路径。

最后，运行这个脚本文件

[cpp] view plain copy

    # sudo sh examples/images/create_lmdb.sh  

就会在examples/images/ 目录下生成一个名为 img_train_lmdb的文件夹，里面的文件就是我们需要的db文件了。

上面就将图像数据转换成db（leveldb/lmdb)文件了。

===================================================================================================================================

再从自己的原始图片到lmdb数据，再到训练和测试模型的整个流程。

一、准备数据

有条件的同学，可以去imagenet的官网http://www.image-net.org/download-images，下载imagenet图片来训练。但是我没有下载，一个原因是注册账号的时候，验证码始终出不来（听说是google网站的验证码，而我是上不了google的）。第二个原因是数据太大了。。。

我去网上找了一些其它的图片来代替，共有500张图片，分为大巴车、恐龙、大象、鲜花和马五个类，每个类100张。需要的同学，可到我的网盘下载：http://pan.baidu.com/s/1nuqlTnN

编号分别以3，4，5，6，7开头，各为一类。我从其中每类选出20张作为测试，其余80张作为训练。因此最终训练图片400张，测试图片100张，共5类。我将图片放在caffe根目录下的data文件夹下面。即训练图片目录：data/re/train/ ,测试图片目录: data/re/test/

二、转换为lmdb格式

具体的转换过程，可参见我的前一篇博文：Caffe学习系列(11)：图像数据转换成db（leveldb/lmdb)文件

首先，在examples下面创建一个myfile的文件夹，来用存放配置文件和脚本文件。然后编写一个脚本create_filelist.sh，用来生成train.txt和test.txt清单文件

[cpp] view plain copy

    # sudo mkdir examples/myfile  
    # sudo vi examples/myfile/create_filelist.sh  

编辑此文件，写入如下代码，并保存

[cpp] view plain copy

    #!/usr/bin/env sh  
    DATA=data/re/  
    MY=examples/myfile  
      
    echo "Create train.txt..."  
    rm -rf $MY/train.txt  
    for i in 3 4 5 6 7   
    do  
    find $DATA/train -name $i*.jpg | cut -d '/' -f4-5 | sed "s/$/ $i/">>$MY/train.txt  
    done  
    echo "Create test.txt..."  
    rm -rf $MY/test.txt  
    for i in 3 4 5 6 7  
    do  
    find $DATA/test -name $i*.jpg | cut -d '/' -f4-5 | sed "s/$/ $i/">>$MY/test.txt  
    done  
    echo "All done"  

然后，运行此脚本

[cpp] view plain copy

    # sudo sh examples/myfile/create_filelist.sh  

成功的话，就会在examples/myfile/ 文件夹下生成train.txt和test.txt两个文本文件，里面就是图片的列表清单。

接着再编写一个脚本文件，调用convert_imageset命令来转换数据格式。

[cpp] view plain copy

    # sudo vi examples/myfile/create_lmdb.sh  

插入：

[cpp] view plain copy

    #!/usr/bin/env sh  
    MY=examples/myfile  
      
    echo "Create train lmdb.."  
    rm -rf $MY/img_train_lmdb  
    build/tools/convert_imageset \  
    --shuffle \  
    --resize_height=256 \  
    --resize_width=256 \  
    /home/xxx/caffe/data/re/ \  
    $MY/train.txt \  
    $MY/img_train_lmdb  
      
    echo "Create test lmdb.."  
    rm -rf $MY/img_test_lmdb  
    build/tools/convert_imageset \  
    --shuffle \  
    --resize_width=256 \  
    --resize_height=256 \  
    /home/xxx/caffe/data/re/ \  
    $MY/test.txt \  
    $MY/img_test_lmdb  
      
    echo "All Done.."  

因为图片大小不一，因此我统一转换成256*256大小。运行成功后，会在 examples/myfile下面生成两个文件夹img_train_lmdb和img_test_lmdb，分别用于保存图片转换后的lmdb文件。

三、计算均值并保存

图片减去均值再训练，会提高训练速度和精度。因此，一般都会有这个操作。

caffe程序提供了一个计算均值的文件compute_image_mean.cpp，我们直接使用就可以了
[cpp] view plain copy

    # sudo build/tools/compute_image_mean examples/myfile/img_train_lmdb examples/myfile/mean.binaryproto  

compute_image_mean带两个参数，第一个参数是lmdb训练数据位置，第二个参数设定均值文件的名字及保存路径。运行成功后，会在 examples/myfile/ 下面生成一个mean.binaryproto的均值文件。

四、创建模型并编写配置文件

模型就用程序自带的caffenet模型，位置在 models/bvlc_reference_caffenet/文件夹下, 将需要的两个配置文件，复制到myfile文件夹内

[cpp] view plain copy

    # sudo cp models/bvlc_reference_caffenet/solver.prototxt examples/myfile/  
    # sudo cp models/bvlc_reference_caffenet/train_val.prototxt examples/myfile/  

修改其中的solver.prototxt

[cpp] view plain copy

    # sudo vi examples/myfile/solver.prototxt  

[cpp] view plain copy

    net: "examples/myfile/train_val.prototxt"  
    test_iter: 2  
    test_interval: 50  
    base_lr: 0.001  
    lr_policy: "step"  
    gamma: 0.1  
    stepsize: 100  
    display: 20  
    max_iter: 500  
    momentum: 0.9  
    weight_decay: 0.005  
    solver_mode: GPU  


100个测试数据，batch_size为50，因此test_iter设置为2，就能全cover了。在训练过程中，调整学习率，逐步变小。

修改train_val.protxt，只需要修改两个阶段的data层就可以了，其它可以不用管。

[cpp] view plain copy

    name: "CaffeNet"  
    layer {  
      name: "data"  
      type: "Data"  
      top: "data"  
      top: "label"  
      include {  
        phase: TRAIN  
      }  
      transform_param {  
        mirror: true  
        crop_size: 227  
        mean_file: "examples/myfile/mean.binaryproto"  
      }  
      data_param {  
        source: "examples/myfile/img_train_lmdb"  
        batch_size: 256  
        backend: LMDB  
      }  
    }  
    layer {  
      name: "data"  
      type: "Data"  
      top: "data"  
      top: "label"  
      include {  
        phase: TEST  
      }  
      transform_param {  
        mirror: false  
        crop_size: 227  
        mean_file: "examples/myfile/mean.binaryproto"  
      }  
      data_param {  
        source: "examples/myfile/img_test_lmdb"  
        batch_size: 50  
        backend: LMDB  
      }  
    }  


实际上就是修改两个data layer的mean_file和source这两个地方，其它都没有变化 。

五、训练和测试

如果前面都没有问题，数据准备好了，配置文件也配置好了，这一步就比较简单了。
[cpp] view plain copy

    # sudo build/tools/caffe train -solver examples/myfile/solver.prototxt  

运行时间和最后的精确度，会根据机器配置，参数设置的不同而不同。我的是gpu+cudnn运行500次，大约8分钟，精度为95%。


﻿﻿
